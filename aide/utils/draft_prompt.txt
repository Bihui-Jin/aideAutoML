Your task is to FILL IN the provided Python Code Template as the returned markdown code block so that it becomes a fully working, self-contained NAS script using **PyGlove** and **PyTorch** and can achieve the best competition metric in the task. You must (1) analyze the competition and dataset descriptions, (2) infer the task type and metric, (3) build a symbolic search space for data processing, model architectures (including **HuggingFace Transformers**), optimizer/training strategies, and (4) train/evaluate and save a valid submission.

########### ABSOLUTE REQUIREMENTS ###########
- Frameworks: Use **PyTorch** (run on GPU via `DEVICE`). You may instantiate **Mixture-of-Experts (MoE)**, use **scikit-learn** for preprocessing, and integrate **HuggingFace Transformers** or **timm** backbones where appropriate. 
- Search Spaces (PyGlove): Define **all tunable knobs** with `pg.oneof([candidates])` (choose 1 out of N candidates), `pg.floatv(min, max)` (a float value from R[min,max]), `pg.manyof(K, [candidates], θ)` (choose K out of N candidates with optional constraints θ on the uniqueness and order of chosen candidates), or `pg.permutate([candidates])` (a special case of manyof which searches for a permutation of all candidates).  
  - Do **NOT** pass `default` to `pg.oneof` (not supported).  
  - Every symbolic choice must have concrete candidate values so the script runs immediately (no empty candidate sets).
- Keep the provided class/method signatures and the outer NAS loop/timeout helper **unchanged**.
- Decorate `Experiment` with `@pg.symbolize` and fill:
  - `__init__`: Declare symbolic knobs for **data processing**, **model family**, **optimizer**, and **training**.
  - `data_processing(...)`: Implement a **competition-aware** pipeline; expose a *symbolic* preprocessing search space. Must support BOTH:
    1) **Transformer/Text branch** (when task is text): build a tokenizer with `AutoTokenizer.from_pretrained(backbone, use_fast=True, trust_remote_code=True, token=auth_token)` and produce **dict tensors** with keys `input_ids`, `attention_mask`, and include `token_type_ids` when present; **symbolic `max_length ∈ {128, 256, 384}`**.  
    2) **Classical branch**: TF-IDF/Hashing (+ optional SVD) producing dense features; **symbolic** representation choice, ngram ranges, max_features, and optional SVD dims.
    Choose branch via a **symbolic knob** (e.g., `pg.oneof(['transformer','tfidf'])`) while still auto-detecting task type from the dataset description.
  - `model(...)`: Return a model moved to `DEVICE`. **Model family knob MUST include ALL of the latest and robust classic, Deep & Cross Network (DCN), and HF options** (at least 6 options for each). Do not use the HF Transformer released before 2023.  
    - If a Transformer is selected: load with `AutoModelForSequenceClassification.from_pretrained(backbone, num_labels=NUM_LABELS, trust_remote_code=True, token=auth_token)`.  
    - If classic: expose complex layers/widths/activations/dropouts (and MoE experts/routing). Ensure logits shape and dtype are consistent with the task.
  - `_optimizer(...)`: Choose from `pg.oneof(['Adam','AdamW','SGD','RMSprop', etc.])` as blow suggested. 
  - `training(...)`: Implement a proper loop with **symbolic** `epochs`, `batch_size` (grid sized for GPU memory, e.g., `{8, 16, 32}` for Transformers; `{64, 128, 256}` for classics), optional **gradient_accumulation_steps ∈ {1,2,4,8}**, **AMP** (`torch.cuda.amp.autocast` + `GradScaler`) and **early stopping** knobs `{enabled ∈ {True,False}, patience ∈ {2,3,4}, min_delta ∈ {0.0, 1e-4}}`.  
    - **Shape/contracts**:
      *Classic branch*: batches are `(X, y)` dense tensors.  
      *Transformer branch*: batches are `({'input_ids','attention_mask', optional 'token_type_ids'}, y)` dicts.  
    - **OOM Backoff (required)**: If CUDA OOM occurs in a Transformer run, automatically retry once with **smaller `batch_size` and/or smaller `max_length`** (halve batch_size; then reduce max_length to next lower grid value), then continue. Clear cache with `torch.cuda.empty_cache()` between retries/trials.
  - `evaluation(...)`: Compute and return the **competition metric**. For lower-is-better metrics (e.g., RMSE), return its **negative** value. 
  - `run(...)`: Build features; split train/valid (stratified for classification). Train, compute `score`, then **refit on full train** with the same hyperparameters (may skip early stop here for speed). Predict test probabilities in the correct order and `return (score, test_probs)`.
- Explicit Knob Declarations (force concrete candidate lists): You MUST declare the following search-space candidates exactly as listed below:
  - classic_arch is to list all kinds of classic architectures, e.g., mlp, RandomForest, moe, dcn, hf, where hf switches the pipeline into the Transformer branch; all other options are classic/tabular/text-classic branches. Keep "hf" in classic_arch to route the Transformer branch.
  - hf_backbone is to list at least 6 robust models from HuggingFace (post-2023 only), e.g., Qwen/Qwen2-1.5B-Instruct and Alibaba-NLP/gte-base-en-v1.5.
- Save a valid **submission** at `submission/submission.csv` with correct columns/format inferred from the instructions.
- **Do NOT add any new print/logging statements anywhere.** Do not log while saving the CSV.

########### COMPETITION-AWARE IMPLEMENTATION ###########
Select the relevant subset based on task type you infer from the competition text:
1) **Data Processing Search Space (`data_processing`)** Suggestions
   - For TEXT / NLP / QA / TEXT MATCHING / TOXICITY / SENTIMENT tasks:
     - Augmentations: SubwordRegularization (SentencePiece), symmetric swaps (response_a↔b TTA), Random undersampling for imbalance.
     - Features / preprocessing: rigorous TextCleaning (lowercase, URLs/HTML/punct/emoji/digits, contractions, misspellings), Tokenization (WordPiece/BPE; attention masks), Padding/Truncation, TF-IDF/Count + SVD, NB-SVM log-count ratio, length/structure counts, similarities (cosine/Jaccard/Levenshtein), OneHot/LabelEncoding for categories, distribution alignment if targets bounded.
     - QA specifics: SlidingWindow with doc_stride, span post-cleaning, char-level aggregation via offset_mapping.
     - Consider symbolic knobs but **not limit to**: representation (`pg.oneof(['tfidf_word','tfidf_char_wb','hashing_word', etc])`), ngram ranges, max_features / hashing n_features, sublinear_tf/use_idf/norm, optional SVD dims (`'none','svd256','svd512'`), stopwords, text-length features on/off, numeric side-channel scaler (`'standard','robust','none'`), optional log1p for heavy-tailed numeric features.
   - For TABULAR tasks:
     - Imbalance: SMOTE / undersampling; for ensembles use Bootstrapping.
     - Preprocessing: Imputation (mean/median/mode/KNN), Standardization/Robust/MinMax, Log/Power transforms (including target via TransformedTargetRegressor).
     - Encodings: OneHot, Label/Ordinal, TargetEncoding, frequency/count encodings; careful leakage control with CV.
     - Feature crafting: polynomial/interactions, correlation filtering, low-variance drop, PCA/SVD, adversarial validation pruning, domain distances (geo Haversine/bearings; airport/landmark distances), string parsing to structured fields.
     - Consider symbolic knobs but not limited to: Imputation knob (`'zero','median'`), scaler knob (`'standard','robust','none'`).
   - For IMAGE CLASSIFICATION (classification/detection/segmentation) tasks:
     - Augmentations to consider
       - Class imbalance or small data: RandomOversampling / Undersampling, MixUp, TTA (flip/rotate/scale).
       - Invariance to pose/orientation: Flip (H/V), Rotate/RandomRotate90, ShiftScaleRotate, Translation, Zoom/Scale, Shear, Warp/GridDistortion.
       - Robustness to lighting/color/camera: ColorJitter (brightness/contrast/saturation/hue), Gamma, CLAHE, HueSaturationValue.
       - Regularization on textures/artefacts: CutOut/CoarseDropout, Blur/NoiseInjection, JPEG artefact sim (JpegCompression).
       - Inference ensembling: TTA (flip/rot/multi-scale), Weighted Boxes Fusion for detections.
     - Feature engineering / preprocessing
       - Always: Resize to backbone input; Normalization/MinMaxScaling; Standardization to ImageNet mean/std or model-specific preprocess_input.
       - Medical/DICOM: VOILUT, HU rescaling, Photometric inversion fix, Center/ROI crop, Padding to aspect, ChannelReplication for 1→3ch, Orientation correction.
       - Gigapixel/volumes: SlidingWindow/Tiling with Overlap blending; Slice stacking or Depth pooling for 2.5D; Resampling-3D.
       - Label format needs: OneHot/MultiLabelBinarization, bbox format conversions; per-class Thresholding / small-object removal.
     - Consider symbolic knobs but not limited to: complex torchvision transforms choices (resize, crop, flip), normalize on/off; but keep light for runtime. 
   - For AUDIO tasks:
     - Augmentations: TimeShift, RandomCrop on spectrograms, NoiseInjection, SilenceTrim, WaveletDenoising, FrequencyFiltering, TTA.
     - Features: MelSpectrogram (+ dB/log), MFCC, spectral stats (centroid/rolloff/ZCR), Fixed-length padding/truncation, Standardization/MinMaxScaling, classic stats aggregation.
   - For TIME SERIES / SEQUENCES (ventilator, GNSS, EEG, volcano, OSIC) tasks:
     - Augmentations / expansions: Smoothing/KalmanSmoothing, NoiseDenoising, OutlierClipping, Intra-entity pair/window sampling.
     - Features: windowed Lag/Diff/Derivative, Rolling stats/quantiles/EWMs, Cumsum/area/integrals, interaction FeatureCrosses, GroupBy aggregates, ClusteringFeatures, Time deltas/indices, domain filters (bandpass for EEG, satellite selection for GNSS).
     - Preprocessing: Imputation (careful per entity), Robust/Standard/MinMax scaling (fit on train only), SequenceReshaping to (T, F), GroupKFold/group-aware CV to avoid leakage, postprocess to valid grids (e.g., rounding pressure to known steps).
   - For RECSYS / RANKING tasks:
     - Features: Label/TargetEncoding of IDs, DatetimeFeatures (recency, cycles), Imputation for demographics, embedding L2 normalization, co-occurrence; for ranking tasks, percentile ranks, position bias indicators.
   - For STEGANALYSIS / REMOTE SENSING / SPECIAL DOMAINS tasks:
     - Augmentations: rotations/flips; JPEG artefact simulation for steganalysis; undersampling negatives (contrails).
     - Features: false-color composites, temporal stacking/aggregation, intensity clipping, heuristic thresholding for masks.
   - Return both features `(X_all, X_test)` (and any IDs if needed inside `run()`), but keep method signature as in the template.
   - Consider to use bootstrap if beneficial.

2) **Model Architecture Search Space (model)** Suggestions
   - For NLP / TEXT PAIRING / QA / SENTIMENT / ARENA tasks:
     - Consider but **not limit to**: use pg.oneof to select from transformers (DeBERTaV3/RemBERT/MuRIL/SentenceTransformer/LLaMA), RandomForest, LogReg, SVM, NaiveBayes, etc.

   - For IMAGE CLASSIFICATION tasks:
     - Consider but **not limit to**: use pg.oneof to select from transformers (ViT-B/L-16/32, DeiT, Swin-T), hybrid conv-attention models (CoAtNet, MaxViT/MaxxViT, MobileViT, EfficientFormer), modern CNNs (ConvNeXt/ConvNeXtV2, EfficientNetV2, NFNet, ResNet-50/101/152, ResNeSt, BiT, RexNet), MLP, tree ensembles (XGBoost, LightGBM, CatBoost, RandomForest, ExtraTrees), linear baselines (LogisticRegression, SVM), and PCA for dimensionality reduction, etc.
  
   - For TIME SERIES / SEQUENCE  tasks (e.g., tabular, sensors, bio, ventilator, GNSS, EEG):
     - Consider but **not limit to**: use pg.oneof to select from transformers (Transformer), sequence RNNs (LSTM/GRU), convolutional (CNN), graph (GNN), autoencoders (Autoencoder/Denoising AE), boosting & tree ensembles (LightGBM/XGBoost/CatBoost), linear models (Linear/ElasticNet/Ridge/Lasso), and kernel methods (SVR), etc.

   - For OBJECT DETECTION tasks:
     - Consider but **not limit to**: use pg.oneof to select from transformer detectors (DETR/YOLOS), one-stage conv detectors (YOLOv5 via torch.hub.load('ultralytics/yolov5'), EfficientDet), mobile backbones (MobileViT), and semantic segmentation (DeepLabv3), etc.

   - For RECOMMENDATION / CTR tasks:
     - Consider but **not limit to**: use pg.oneof to select from collaborative filtering (ALS), sequential recommenders (GRU4Rec/LSTM/CNN), and boosted trees for tabular/context features (gradient boosting), etc.

   - For AUDIO (spectrogram / waveform) tasks:
     - Consider but **not limit to**: use pg.oneof to select from convolutional nets (ResNet-50/101/152/CNN), sequence RNNs (LSTM/GRU), and boosting & tree ensembles, etc.

   - For RETRIEVAL/RANKING / METRICS LEARNING tasks:
     - Consider but **not limit to**: use pg.oneof to select from metric-learning architectures (Siamese Network) and classic text pipelines (TF-IDF + linear/trees stacks), etc.

   - For SPECIALIZED / OTHER tasks:
     - Consider but **not limit to**: use pg.oneof to select from unsupervised clustering (k-Means), dimensionality reduction / representation (PCA), image-to-image generative models (CycleGAN, TensorFlow), and search/meta-optimization (GeneticAlgorithm), etc.

3) **Optimizer & Training Search Space** Suggestions
   - `_optimizer`: Consider symbolic knobs but **not limit to**: use pg.oneof to select from Adam, AdamW, RMSprop, SGD, Momentum, Nesterov, Nadam, Adamax, Adagrad, Adadelta, LBFGS, SAGA, SAG, Newton-CG, liblinear, RectifiedAdam, Lookahead, MADGRAD, SLSQP, Nelder-Mead, etc.
   - `training`: implement a mini training loop over `epochs` (e.g., {4,5}) with `batch_size` choices (e.g., {128,256}), criterion choice could be:
     - Binary classification: `BCEWithLogitsLoss`.
     - Multiclass: `CrossEntropyLoss`.
     - Regression: `MSELoss` (report negative RMSE as score for “higher-is-better” convention).
   - Optional early stopping knobs: `{enabled ∈ {True,False}, patience ∈ {2,3,4}, min_delta ∈ {0.0,1e-4}}`. If enabled, monitor validation metric and restore best weights.

4) **smoke_test()** requirements (fast, minimal sanity run)
You MUST implement smoke_test() to run **two ultra-short** trials-one per family—to catch shallow bugs quickly without altering the main NAS loop:
   - Run matrix: Execute:
     - Exactly one HF trial using the first candidate from `hf_backbone` (respecting the tokenizer/model path and collate for dict-inputs).
     - All classic arches (i.e., iterate through every non-"hf" option listed in `classic_arch`) with the classic/dense pipeline and collate.
     - Always instantiate `Experiment` by setting every declared knob declared in `__init__` in a single constructor call, choosing one valid option for each pg.oneof/manyof/floatv knob; knobs should be consistent for either the HF or classic branch.
     - Reuse the existing run_with_timeout.
   - Transformer family smoke test:
     - Construct a minimal Experiment with:
       - `classic_arch='hf'`,
       - `hf_backbone=pg.oneof([...])` but **force one** concrete pick for the smoke test (e.g., the first in the `hf_backbone` list),
       - max_length=128, batch_size_transformer=8, epochs=1, gradient_accumulation_steps=1, Automatic Mixed Precision (torch.amp) enabled, early stopping disabled.
     - Create a **tiny** sample dataset (e.g., take only the first 8 rows of train, 2 rows of valid, and 2 rows of test or synthesize two short strings with binary labels if the competition files are missing).
     - Run end-to-end: data_processing → model → training → evaluation → run() and assert:
       - The forward pass completes on DEVICE.
       - Output logits/probabilities have expected shapes.
       - Do **not** save submission CSV for the smoke test.
   - Classic family smoke test:
     - Construct a minimal Experiment with each one in classic_arch:
       - `classic_arch='dcn2'`,
       - A classic text/tabular preprocessing setting (e.g., 'tfidf_word' with a tiny max_features=1024 and SVD on),
       - batch_size_classic=64, epochs=1, early stopping disabled.
     - Use the same tiny sample dataset protocol (first few rows).
     - Run end-to-end with the same assertions as above.
   - General smoke-test rules:
     - With PyGlove `.rebind()`, a symbolic object can be manipluated into another object without modifying existing code; rebind(x, dict) is used to replace each node in x whose path is a key in dict, e.g., experiment.rebind({'classic_arch':'mlp'}) setting self.classic_arch='mlp'.
     - Use `.clone()` before using `.rebind`, e.g., `exp1 = Experiment().clone().rebind(...)`, to ensure no effect to the main branch.
     - Do not print; Do not save submission CSV; reuse the existing run_with_timeout.
     - Ensure both branches return (score, test_probs).
     - epochs = 1, batch_size minimal (e.g., 8 for HF, 64 for classic).
     - AMP on, gradient accumulation = 1.
     - No early stopping.
     - Make sure each architecture option is only run once

5) **run()**
   - Build features.
   - Stratified (if classification) hold-out split (`valid_size=0.2`) for quick feedback.
   - Train and compute validation metric via `evaluation`.
   - Refit on full train with same hyperparams (you can skip early stop here for speed).
   - Predict test set probabilities in correct order.
   - Return `(score, test_probs)`.

######################## TRANSFORMER REQUIREMENTS (MANDATORY) ########################
- **Search space must include robust HF backbones** (released after 2023) in `pg.oneof`. 
- **Always fine-tune before inference**: train the randomly initialized classifier head (and optionally top transformer layers).
- **Runtime & robustness**: Enable **early stopping**; **OOM backoff** as specified above; call `torch.cuda.empty_cache()` and `gc.collect()` between trials.
- **GPU memory**: Be mindful of GPU memory (48 GB). Mush choose models wisely to avoid OOM.  


########### IMPLEMENTATION TIPS TO IMPROVE CODE QUALITY (CROSS-CUTTING) ###########
- Search space should be large: each pg.oneof should offer at least 10 options.
- Separate train/val/test transforms; avoid leakage (fit scalers on train only).  
- For tokenizers/models, pass the HF auth token via `auth_token = os.getenv("HUGGINGFACE_KEY")`.  
- Prefer mixed precision for Transformers; consider activation checkpointing if easily available.  
- When using AutoModelForSequenceClassification with a fresh head; treat it as info, not an error.
- When loading any HF checkpoint, ensure the classifier head matches the target classes (e.g., explicitly set num_labels=2 in the config and pass ignore_mismatched_sizes=True). Prefer base checkpoints (not task-specific variants like -mnli) to avoid head size mismatches.
- When building transformer batches, pass only the fields returned by the tokenizer-do not synthesize token_type_ids if they are not provided. Ensure the **inputs you pass to model(**inputs) match the selected backbone's accepted arguments.
- If a HF backbone is chosen, build only the HF model; keep BCE shapes consistent (logits.view(-1,1) vs y.view(-1,1)) and avoid mixing classic/transformer collates.
- Enforce a single data/model branch per trial. If model_family contains HF backbone, force to use TransformerTextDataset + make_transformer_collate, batch_size_transformer, lr_transformer, etc; do not build or consume TF-IDF/Hashing/SVD/scalers, and never use ClassicTensorDataset/classic_collate. If model_family is classic, force to use dense features with ClassicTensorDataset + classic_collate, batch_size_classic, lr_classic, etc; do not instantiate HF tokenizer/model/collate or feed dict-style batches. Insert hard checks: raise if (HF ∧ classic features/collate) or (classic ∧ transformer tokenizer/collate). Maintain consistency across training/validation/test loaders.
- Diagnose and fix the transformer branch so TransformerDataset never assumes .shape on lists: normalize all tokenizer outputs to NumPy arrays (e.g., {k: np.asarray(v, dtype=np.int64)}) or PyTorch tensors before dataset creation, and compute length with len(encodings["input_ids"]).
- Ensure the entire classic pipeline produces identical feature dimensions for train and test before SVD: fit the vectorizer(s) and any numeric scaler on train only, transform both sets in the same order, assert X_test.shape[1] == X_train.shape[1] prior to svd.transform, and if not, rebuild X_test using the exact fitted vectorizer(s)/column order (or skip SVD when dims differ).

Now, FILL IN THE TEMPLATE:
- Declare all PyGlove knobs in `__init__`.
- Implement `data_processing`, `model`, `_optimizer`, `training`, `evaluation`, `run` exactly as specified above.
- Ensure `run()` returns `(score, test_probs)` and that the code runs end-to-end without modification.
